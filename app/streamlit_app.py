import streamlit as st
import pandas as pd
import joblib
import os

# ==============================
# ğŸ”§ Model Configuration
# ==============================
MODEL_DIR = "../models/"
DATA_PATH = "../data/processed/web_feed.csv"
SCALER_PATH = "../models/feature_scaler.pkl"

MODELS = {
    "top1_AdaBoost.pkl": "AdaBoost ",
    "top6_LightGBM.pkl": "LightGBM ",
    "top5_ExtraTrees.pkl": "Extra Trees(57)",
    "top4_RandomForest.pkl": "Random Forest",
    "top8_XGBoost.pkl": "XGBoost ",
    "top7_SVM.pkl": "Support Vector Machineâ­ (Best Trader)",
    "top2_GradientBoost.pkl": "Gradient Boosting",
    "top3_LogisticRegression.pkl": "Logistic Regression(57)"
}

# ==============================
# ğŸ¨ Page Setup
# ==============================
st.set_page_config(page_title="NIFTY50 Predictor", page_icon="ğŸ“ˆ", layout="wide")
st.title("ğŸ“ˆ NIFTY50 Next-Day Direction Prediction App")
st.markdown(
    "This app uses **7 Machine Learning Models** to predict whether NIFTY50 will go "
    "**Up ğŸ“ˆ** or **Down ğŸ“‰** on the next trading day."
)

# ==============================
# ğŸ“¥ Load Scaler
# ==============================
scaler = joblib.load(SCALER_PATH)

# ==============================
# ğŸ“¥ Load All Models
# ==============================
loaded_models = {}
st.subheader("ğŸ”„ Loading Models...")

for model_file, display_name in MODELS.items():
    model_path = os.path.join(MODEL_DIR, model_file)
    if os.path.exists(model_path):
        try:
            loaded_models[display_name] = joblib.load(model_path)
            st.success(f"âœ… Loaded: {display_name}")
        except Exception as e:
            st.error(f"âŒ Failed to load {model_file}: {e}")
    else:
        st.warning(f"âš ï¸ Model file not found: {model_file}")

if not loaded_models:
    st.error("âŒ No models loaded successfully.")
    st.stop()

st.success(f"âœ… Successfully loaded {len(loaded_models)} models!")

# ==============================
# ğŸ“Š Load Data
# ==============================
data = pd.read_csv(DATA_PATH)

st.subheader("ğŸ“„ Latest Available Data")
st.dataframe(data.tail(5))

# ==============================
# ğŸ§  Make Predictions
# ==============================
st.subheader("ğŸ”® Model Predictions")

latest_features = data.iloc[-1:].copy()
latest_features_scaled = pd.DataFrame(
    scaler.transform(latest_features),
    columns=latest_features.columns
)

predictions_data = []
up_votes = 0
down_votes = 0
up_probabilities = []

col1, col2 = st.columns(2)

for idx, (model_name, model) in enumerate(loaded_models.items()):
    expected_features = model.n_features_in_

    if latest_features_scaled.shape[1] != expected_features:
        st.warning(f"âš ï¸ Feature mismatch for {model_name}")
        continue

    prediction = model.predict(latest_features_scaled)[0]
    proba = model.predict_proba(latest_features_scaled)[0]

    up_probabilities.append(proba[1])

    if prediction == 1:
        up_votes += 1
    else:
        down_votes += 1

    predictions_data.append({
        "Model": model_name,
        "Prediction": "ğŸ“ˆ UP" if prediction == 1 else "ğŸ“‰ DOWN",
        "Confidence": f"{float(max(proba)) * 100:.2f}%",
        "Up %": f"{float(proba[1]) * 100:.2f}%",
        "Down %": f"{float(proba[0]) * 100:.2f}%"
    })

    with col1 if idx % 2 == 0 else col2:
        st.markdown(f"### {model_name}")
        if prediction == 1:
            st.success("ğŸ“ˆ UP")
        else:
            st.error("ğŸ“‰ DOWN")
        st.progress(float(proba[1]))

# ==============================
# ğŸ“Š Summary
# ==============================
st.subheader("ğŸ“Š Ensemble Summary")

total_models = up_votes + down_votes
avg_up_probability = sum(up_probabilities) / len(up_probabilities) * 100 if up_probabilities else 0

majority_direction = "UP ğŸ“ˆ" if up_votes > down_votes else "DOWN ğŸ“‰"
majority_percentage = (max(up_votes, down_votes) / total_models) * 100 if total_models > 0 else 0

st.metric("ğŸ“ˆ UP Predictions", up_votes)
st.metric("ğŸ“‰ DOWN Predictions", down_votes)
st.metric("ğŸ† Majority Vote", majority_direction)
st.metric("ğŸ“Š Majority Confidence", f"{majority_percentage:.2f}%")
st.metric("ğŸ“‰ Avg UP Probability", f"{avg_up_probability:.2f}%")

if predictions_data:
    predictions_df = pd.DataFrame(predictions_data)
    st.dataframe(predictions_df, width="stretch")

# ==============================
# â„¹ï¸ Footer
# ==============================
st.divider()
st.caption("ğŸš€ **Developed by AKSHAT MISHRA** | Models: 7 ML Algorithms | Data: web_feed.csv")
st.caption("âš ï¸ Disclaimer: This is for educational purposes only. Not financial advice.")
